[aihubmix]
id = "aihubmix"
name = "AIHubMix"
env = ["AIHUBMIX_API_KEY"]
npm = "@aihubmix/ai-sdk-provider"
doc = "https://docs.aihubmix.com"
models = ["DeepSeek-V3.2-Exp", "DeepSeek-V3.2-Exp-Think", "Kimi-K2-0905", "claude-haiku-4-5", "claude-opus-4-1", "claude-sonnet-4-5", "gemini-2.5-flash", "gemini-2.5-pro", "glm-4.6", "gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano", "gpt-4o", "gpt-4o-2024-11-20", "gpt-5", "gpt-5-codex", "gpt-5-mini", "gpt-5-nano", "gpt-5-pro", "o4-mini", "qwen3-235b-a22b-instruct-2507", "qwen3-235b-a22b-thinking-2507", "qwen3-coder-480b-a35b-instruct"]

[alibaba]
id = "alibaba"
name = "Alibaba"
env = ["DASHSCOPE_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
doc = "https://www.alibabacloud.com/help/en/model-studio/models"
models = ["qvq-max", "qwen-flash", "qwen-max", "qwen-mt-plus", "qwen-mt-turbo", "qwen-omni-turbo", "qwen-omni-turbo-realtime", "qwen-plus", "qwen-plus-character-ja", "qwen-turbo", "qwen-vl-max", "qwen-vl-ocr", "qwen-vl-plus", "qwen2-5-14b-instruct", "qwen2-5-32b-instruct", "qwen2-5-72b-instruct", "qwen2-5-7b-instruct", "qwen2-5-omni-7b", "qwen2-5-vl-72b-instruct", "qwen2-5-vl-7b-instruct", "qwen3-14b", "qwen3-235b-a22b", "qwen3-32b", "qwen3-8b", "qwen3-asr-flash", "qwen3-coder-30b-a3b-instruct", "qwen3-coder-480b-a35b-instruct", "qwen3-coder-flash", "qwen3-coder-plus", "qwen3-livetranslate-flash-realtime", "qwen3-max", "qwen3-next-80b-a3b-instruct", "qwen3-next-80b-a3b-thinking", "qwen3-omni-flash", "qwen3-omni-flash-realtime", "qwen3-vl-235b-a22b", "qwen3-vl-30b-a3b", "qwen3-vl-plus", "qwq-plus"]

[alibaba-cn]
id = "alibaba-cn"
name = "Alibaba (China)"
env = ["DASHSCOPE_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://dashscope.aliyuncs.com/compatible-mode/v1"
doc = "https://www.alibabacloud.com/help/en/model-studio/models"
models = ["deepseek-r1", "deepseek-r1-0528", "deepseek-r1-distill-llama-70b", "deepseek-r1-distill-llama-8b", "deepseek-r1-distill-qwen-1-5b", "deepseek-r1-distill-qwen-14b", "deepseek-r1-distill-qwen-32b", "deepseek-r1-distill-qwen-7b", "deepseek-v3", "deepseek-v3-1", "deepseek-v3-2-exp", "moonshot-kimi-k2-instruct", "qvq-max", "qwen-deep-research", "qwen-doc-turbo", "qwen-flash", "qwen-long", "qwen-math-plus", "qwen-math-turbo", "qwen-max", "qwen-mt-plus", "qwen-mt-turbo", "qwen-omni-turbo", "qwen-omni-turbo-realtime", "qwen-plus", "qwen-plus-character", "qwen-turbo", "qwen-vl-max", "qwen-vl-ocr", "qwen-vl-plus", "qwen2-5-14b-instruct", "qwen2-5-32b-instruct", "qwen2-5-72b-instruct", "qwen2-5-7b-instruct", "qwen2-5-coder-32b-instruct", "qwen2-5-coder-7b-instruct", "qwen2-5-math-72b-instruct", "qwen2-5-math-7b-instruct", "qwen2-5-omni-7b", "qwen2-5-vl-72b-instruct", "qwen2-5-vl-7b-instruct", "qwen3-14b", "qwen3-235b-a22b", "qwen3-32b", "qwen3-8b", "qwen3-asr-flash", "qwen3-coder-30b-a3b-instruct", "qwen3-coder-480b-a35b-instruct", "qwen3-coder-flash", "qwen3-coder-plus", "qwen3-max", "qwen3-next-80b-a3b-instruct", "qwen3-next-80b-a3b-thinking", "qwen3-omni-flash", "qwen3-omni-flash-realtime", "qwen3-vl-235b-a22b", "qwen3-vl-30b-a3b", "qwen3-vl-plus", "qwq-32b", "qwq-plus", "tongyi-intent-detect-v3"]

[amazon-bedrock]
id = "amazon-bedrock"
name = "Amazon Bedrock"
env = ["AWS_ACCESS_KEY_ID", "AWS_SECRET_ACCESS_KEY", "AWS_REGION"]
npm = "@ai-sdk/amazon-bedrock"
doc = "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html"
models = ["ai21.jamba-1-5-large-v1:0", "ai21.jamba-1-5-mini-v1:0", "amazon.nova-lite-v1:0", "amazon.nova-micro-v1:0", "amazon.nova-premier-v1:0", "amazon.nova-pro-v1:0", "anthropic.claude-3-5-haiku-20241022-v1:0", "anthropic.claude-3-5-sonnet-20240620-v1:0", "anthropic.claude-3-5-sonnet-20241022-v2:0", "anthropic.claude-3-7-sonnet-20250219-v1:0", "anthropic.claude-3-haiku-20240307-v1:0", "anthropic.claude-3-opus-20240229-v1:0", "anthropic.claude-3-sonnet-20240229-v1:0", "anthropic.claude-haiku-4-5-20251001-v1:0", "anthropic.claude-instant-v1", "anthropic.claude-opus-4-1-20250805-v1:0", "anthropic.claude-opus-4-20250514-v1:0", "anthropic.claude-sonnet-4-20250514-v1:0", "anthropic.claude-sonnet-4-5-20250929-v1:0", "anthropic.claude-v2", "anthropic.claude-v2:1", "cohere.command-light-text-v14", "cohere.command-r-plus-v1:0", "cohere.command-r-v1:0", "cohere.command-text-v14", "deepseek.r1-v1:0", "meta.llama3-1-70b-instruct-v1:0", "meta.llama3-1-8b-instruct-v1:0", "meta.llama3-2-11b-instruct-v1:0", "meta.llama3-2-1b-instruct-v1:0", "meta.llama3-2-3b-instruct-v1:0", "meta.llama3-2-90b-instruct-v1:0", "meta.llama3-3-70b-instruct-v1:0", "meta.llama3-70b-instruct-v1:0", "meta.llama3-8b-instruct-v1:0", "meta.llama4-maverick-17b-instruct-v1:0", "meta.llama4-scout-17b-instruct-v1:0"]

[anthropic]
id = "anthropic"
name = "Anthropic"
env = ["ANTHROPIC_API_KEY"]
npm = "@ai-sdk/anthropic"
doc = "https://docs.anthropic.com/en/docs/about-claude/models"
models = ["claude-3-5-haiku-20241022", "claude-3-5-haiku-latest", "claude-3-5-sonnet-20240620", "claude-3-5-sonnet-20241022", "claude-3-7-sonnet-20250219", "claude-3-7-sonnet-latest", "claude-3-haiku-20240307", "claude-3-opus-20240229", "claude-3-sonnet-20240229", "claude-haiku-4-5", "claude-haiku-4-5-20251001", "claude-opus-4-0", "claude-opus-4-1", "claude-opus-4-1-20250805", "claude-opus-4-20250514", "claude-sonnet-4-0", "claude-sonnet-4-20250514", "claude-sonnet-4-5", "claude-sonnet-4-5-20250929"]

[azure]
id = "azure"
name = "Azure"
env = ["AZURE_RESOURCE_NAME", "AZURE_API_KEY"]
npm = "@ai-sdk/azure"
doc = "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models"
models = ["codex-mini", "gpt-3.5-turbo-0125", "gpt-3.5-turbo-0301", "gpt-3.5-turbo-0613", "gpt-3.5-turbo-1106", "gpt-3.5-turbo-instruct", "gpt-4", "gpt-4-32k", "gpt-4-turbo", "gpt-4-turbo-vision", "gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano", "gpt-4o", "gpt-4o-mini", "gpt-5", "gpt-5-chat", "gpt-5-codex", "gpt-5-mini", "gpt-5-nano", "o1", "o1-mini", "o1-preview", "o3", "o3-mini", "o4-mini"]

[baseten]
id = "baseten"
name = "Baseten"
env = ["BASETEN_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://inference.baseten.co/v1"
doc = "https://docs.baseten.co/development/model-apis/overview"
models = ["Qwen3/Qwen3-Coder-480B-A35B-Instruct", "moonshotai/Kimi-K2-Instruct-0905", "zai-org/GLM-4.6"]

[cerebras]
id = "cerebras"
name = "Cerebras"
env = ["CEREBRAS_API_KEY"]
npm = "@ai-sdk/cerebras"
doc = "https://inference-docs.cerebras.ai/models/overview"
models = ["gpt-oss-120b", "qwen-3-235b-a22b-instruct-2507", "qwen-3-coder-480b"]

[chutes]
id = "chutes"
name = "Chutes"
env = ["CHUTES_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://llm.chutes.ai/v1"
doc = "https://llm.chutes.ai/v1/models"
models = ["Qwen/Qwen3-235B-A22B-Instruct-2507", "Qwen/Qwen3-235B-A22B-Thinking-2507", "Qwen/Qwen3-30B-A3B", "Qwen/Qwen3-30B-A3B-Instruct-2507", "Qwen/Qwen3-30B-A3B-Thinking-2507", "Qwen/Qwen3-Coder-30B-A3B-Instruct", "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8", "Qwen/Qwen3-Next-80B-A3B-Instruct", "Qwen/Qwen3-Next-80B-A3B-Thinking", "chutesai/Devstral-Small-2505", "chutesai/Mistral-Small-3.2-24B-Instruct-2506", "deepseek-ai/DeepSeek-R1-0528", "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B", "deepseek-ai/DeepSeek-R1-Distill-Llama-70B", "deepseek-ai/DeepSeek-V3-0324", "deepseek-ai/DeepSeek-V3.1", "deepseek-ai/DeepSeek-V3.1-Terminus", "deepseek-ai/DeepSeek-V3.1-turbo", "deepseek-ai/DeepSeek-V3.1:THINKING", "deepseek-ai/DeepSeek-V3.2-Exp", "meituan-longcat/LongCat-Flash-Chat-FP8", "moonshotai/Kimi-Dev-72B", "moonshotai/Kimi-K2-Instruct-0905", "moonshotai/Kimi-K2-Instruct-75k", "moonshotai/Kimi-VL-A3B-Thinking", "openai/gpt-oss-120b", "tngtech/DeepSeek-R1T-Chimera", "tngtech/DeepSeek-TNG-R1T2-Chimera", "zai-org/GLM-4.5-Air", "zai-org/GLM-4.5-FP8", "zai-org/GLM-4.5-turbo", "zai-org/GLM-4.6-FP8", "zai-org/GLM-4.6-turbo"]

[cloudflare-workers-ai]
id = "cloudflare-workers-ai"
name = "Cloudflare Workers AI"
env = ["CLOUDFLARE_ACCOUNT_ID", "CLOUDFLARE_API_KEY"]
npm = "workers-ai-provider"
doc = "https://developers.cloudflare.com/workers-ai/models/"
models = ["aura-1", "bart-large-cnn", "deepseek-coder-6.7b-base-awq", "deepseek-coder-6.7b-instruct-awq", "deepseek-math-7b-instruct", "deepseek-r1-distill-qwen-32b", "discolm-german-7b-v1-awq", "dreamshaper-8-lcm", "falcon-7b-instruct", "flux-1-schnell", "gemma-2b-it-lora", "gemma-3-12b-it", "gemma-7b-it", "gemma-7b-it-lora", "gpt-oss-120b", "gpt-oss-20b", "hermes-2-pro-mistral-7b", "llama-2-13b-chat-awq", "llama-2-7b-chat-fp16", "llama-2-7b-chat-hf-lora", "llama-2-7b-chat-int8", "llama-3-8b-instruct", "llama-3-8b-instruct-awq", "llama-3.1-70b-instruct", "llama-3.1-8b-instruct", "llama-3.1-8b-instruct-awq", "llama-3.1-8b-instruct-fast", "llama-3.1-8b-instruct-fp8", "llama-3.2-11b-vision-instruct", "llama-3.2-1b-instruct", "llama-3.2-3b-instruct", "llama-3.3-70b-instruct-fp8-fast", "llama-4-scout-17b-16e-instruct", "llama-guard-3-8b", "llamaguard-7b-awq", "llava-1.5-7b-hf", "lucid-origin", "m2m100-1.2b", "melotts", "mistral-7b-instruct-v0.1", "mistral-7b-instruct-v0.1-awq", "mistral-7b-instruct-v0.2", "mistral-7b-instruct-v0.2-lora", "mistral-small-3.1-24b-instruct", "neural-chat-7b-v3-1-awq", "nova-3", "openchat-3.5-0106", "openhermes-2.5-mistral-7b-awq", "phi-2", "phoenix-1.0", "qwen1.5-0.5b-chat", "qwen1.5-1.8b-chat", "qwen1.5-14b-chat-awq", "qwen1.5-7b-chat-awq", "qwen2.5-coder-32b-instruct", "qwq-32b", "resnet-50", "sqlcoder-7b-2", "stable-diffusion-v1-5-img2img", "stable-diffusion-v1-5-inpainting", "stable-diffusion-xl-base-1.0", "stable-diffusion-xl-lightning", "starling-lm-7b-beta", "tinyllama-1.1b-chat-v1.0", "uform-gen2-qwen-500m", "una-cybertron-7b-v2-bf16", "whisper", "whisper-large-v3-turbo", "whisper-tiny-en", "zephyr-7b-beta-awq"]

[cortecs]
id = "cortecs"
name = "Cortecs"
env = ["CORTECS_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.cortecs.ai/v1"
doc = "https://api.cortecs.ai/v1/models"
models = ["claude-4-5-sonnet", "claude-sonnet-4", "deepseek-v3-0324", "gemini-2.5-pro", "gpt-4.1", "gpt-oss-120b", "kimi-k2-instruct", "llama-3.1-405b-instruct", "nova-pro-v1", "qwen3-32b", "qwen3-coder-480b-a35b-instruct"]

[deepinfra]
id = "deepinfra"
name = "Deep Infra"
env = ["DEEPINFRA_API_KEY"]
npm = "@ai-sdk/deepinfra"
doc = "https://deepinfra.com/models"
models = ["Qwen/Qwen3-Coder-480B-A35B-Instruct", "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo", "moonshotai/Kimi-K2-Instruct", "zai-org/GLM-4.5"]

[deepseek]
id = "deepseek"
name = "DeepSeek"
env = ["DEEPSEEK_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.deepseek.com"
doc = "https://platform.deepseek.com/api-docs/pricing"
models = ["deepseek-chat", "deepseek-reasoner"]

[fastrouter]
id = "fastrouter"
name = "FastRouter"
env = ["FASTROUTER_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://go.fastrouter.ai/api/v1"
doc = "https://fastrouter.ai/models"
models = ["anthropic/claude-opus-4.1", "anthropic/claude-sonnet-4", "deepseek-ai/deepseek-r1-distill-llama-70b", "google/gemini-2.5-flash", "google/gemini-2.5-pro", "moonshotai/kimi-k2", "openai/gpt-4.1", "openai/gpt-5", "openai/gpt-5-mini", "openai/gpt-5-nano", "openai/gpt-oss-120b", "openai/gpt-oss-20b", "qwen/qwen3-coder", "x-ai/grok-4"]

[fireworks-ai]
id = "fireworks-ai"
name = "Fireworks AI"
env = ["FIREWORKS_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.fireworks.ai/inference/v1/"
doc = "https://fireworks.ai/docs/"
models = ["accounts/fireworks/models/deepseek-r1-0528", "accounts/fireworks/models/deepseek-v3-0324", "accounts/fireworks/models/deepseek-v3p1", "accounts/fireworks/models/glm-4p5", "accounts/fireworks/models/glm-4p5-air", "accounts/fireworks/models/gpt-oss-120b", "accounts/fireworks/models/gpt-oss-20b", "accounts/fireworks/models/kimi-k2-instruct", "accounts/fireworks/models/qwen3-235b-a22b", "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct"]

[github-copilot]
id = "github-copilot"
name = "GitHub Copilot"
env = ["GITHUB_TOKEN"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.githubcopilot.com"
doc = "https://docs.github.com/en/copilot"
models = ["claude-3.5-sonnet", "claude-3.7-sonnet", "claude-3.7-sonnet-thought", "claude-haiku-4.5", "claude-opus-4", "claude-opus-41", "claude-sonnet-4", "claude-sonnet-4.5", "gemini-2.0-flash-001", "gemini-2.5-pro", "gpt-4.1", "gpt-4o", "gpt-5", "gpt-5-codex", "gpt-5-mini", "grok-code-fast-1", "o3", "o3-mini", "o4-mini"]

[github-models]
id = "github-models"
name = "GitHub Models"
env = ["GITHUB_TOKEN"]
npm = "@ai-sdk/openai-compatible"
api = "https://models.github.ai/inference"
doc = "https://docs.github.com/en/github-models"
models = ["ai21-labs/ai21-jamba-1.5-large", "ai21-labs/ai21-jamba-1.5-mini", "cohere/cohere-command-a", "cohere/cohere-command-r", "cohere/cohere-command-r-08-2024", "cohere/cohere-command-r-plus", "cohere/cohere-command-r-plus-08-2024", "core42/jais-30b-chat", "deepseek/deepseek-r1", "deepseek/deepseek-r1-0528", "deepseek/deepseek-v3-0324", "meta/llama-3.2-11b-vision-instruct", "meta/llama-3.2-90b-vision-instruct", "meta/llama-3.3-70b-instruct", "meta/llama-4-maverick-17b-128e-instruct-fp8", "meta/llama-4-scout-17b-16e-instruct", "meta/meta-llama-3-70b-instruct", "meta/meta-llama-3-8b-instruct", "meta/meta-llama-3.1-405b-instruct", "meta/meta-llama-3.1-70b-instruct", "meta/meta-llama-3.1-8b-instruct", "microsoft/mai-ds-r1", "microsoft/phi-3-medium-128k-instruct", "microsoft/phi-3-medium-4k-instruct", "microsoft/phi-3-mini-128k-instruct", "microsoft/phi-3-mini-4k-instruct", "microsoft/phi-3-small-128k-instruct", "microsoft/phi-3-small-8k-instruct", "microsoft/phi-3.5-mini-instruct", "microsoft/phi-3.5-moe-instruct", "microsoft/phi-3.5-vision-instruct", "microsoft/phi-4", "microsoft/phi-4-mini-instruct", "microsoft/phi-4-mini-reasoning", "microsoft/phi-4-multimodal-instruct", "microsoft/phi-4-reasoning", "mistral-ai/codestral-2501", "mistral-ai/ministral-3b", "mistral-ai/mistral-large-2411", "mistral-ai/mistral-medium-2505", "mistral-ai/mistral-nemo", "mistral-ai/mistral-small-2503", "openai/gpt-4.1", "openai/gpt-4.1-mini", "openai/gpt-4.1-nano", "openai/gpt-4o", "openai/gpt-4o-mini", "openai/o1", "openai/o1-mini", "openai/o1-preview", "openai/o3", "openai/o3-mini", "openai/o4-mini", "xai/grok-3", "xai/grok-3-mini"]

[google]
id = "google"
name = "Google"
env = ["GOOGLE_GENERATIVE_AI_API_KEY", "GEMINI_API_KEY"]
npm = "@ai-sdk/google"
doc = "https://ai.google.dev/gemini-api/docs/pricing"
models = ["gemini-1.5-flash", "gemini-1.5-flash-8b", "gemini-1.5-pro", "gemini-2.0-flash", "gemini-2.0-flash-lite", "gemini-2.5-flash", "gemini-2.5-flash-image", "gemini-2.5-flash-image-preview", "gemini-2.5-flash-lite", "gemini-2.5-flash-lite-preview-06-17", "gemini-2.5-flash-lite-preview-09-2025", "gemini-2.5-flash-preview-04-17", "gemini-2.5-flash-preview-05-20", "gemini-2.5-flash-preview-09-2025", "gemini-2.5-flash-preview-tts", "gemini-2.5-pro", "gemini-2.5-pro-preview-05-06", "gemini-2.5-pro-preview-06-05", "gemini-2.5-pro-preview-tts", "gemini-embedding-001", "gemini-flash-latest", "gemini-flash-lite-latest", "gemini-live-2.5-flash", "gemini-live-2.5-flash-preview-native-audio"]

[google-vertex]
id = "google-vertex"
name = "Vertex"
env = ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"]
npm = "@ai-sdk/google-vertex"
doc = "https://cloud.google.com/vertex-ai/generative-ai/docs/models"
models = ["gemini-2.0-flash", "gemini-2.0-flash-lite", "gemini-2.5-flash", "gemini-2.5-flash-lite", "gemini-2.5-flash-lite-preview-06-17", "gemini-2.5-flash-lite-preview-09-2025", "gemini-2.5-flash-preview-04-17", "gemini-2.5-flash-preview-05-20", "gemini-2.5-flash-preview-09-2025", "gemini-2.5-pro", "gemini-2.5-pro-preview-05-06", "gemini-2.5-pro-preview-06-05", "gemini-embedding-001", "gemini-flash-latest", "gemini-flash-lite-latest"]

[google-vertex-anthropic]
id = "google-vertex-anthropic"
name = "Vertex"
env = ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"]
npm = "@ai-sdk/google-vertex"
doc = "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude"
models = ["claude-3-5-haiku@20241022", "claude-3-5-sonnet@20241022", "claude-3-7-sonnet@20250219", "claude-haiku-4-5@20251001", "claude-opus-4-1@20250805", "claude-opus-4@20250514", "claude-sonnet-4-5@20250929", "claude-sonnet-4@20250514"]

[groq]
id = "groq"
name = "Groq"
env = ["GROQ_API_KEY"]
npm = "@ai-sdk/groq"
doc = "https://console.groq.com/docs/models"
models = ["deepseek-r1-distill-llama-70b", "gemma2-9b-it", "llama-3.1-8b-instant", "llama-3.3-70b-versatile", "llama-guard-3-8b", "llama3-70b-8192", "llama3-8b-8192", "meta-llama/llama-4-maverick-17b-128e-instruct", "meta-llama/llama-4-scout-17b-16e-instruct", "meta-llama/llama-guard-4-12b", "mistral-saba-24b", "moonshotai/kimi-k2-instruct", "moonshotai/kimi-k2-instruct-0905", "openai/gpt-oss-120b", "openai/gpt-oss-20b", "qwen-qwq-32b", "qwen/qwen3-32b"]

[huggingface]
id = "huggingface"
name = "Hugging Face"
env = ["HF_TOKEN"]
npm = "@ai-sdk/openai-compatible"
api = "https://router.huggingface.co/v1"
doc = "https://huggingface.co/docs/inference-providers"
models = ["Qwen/Qwen3-235B-A22B-Thinking-2507", "Qwen/Qwen3-Coder-480B-A35B-Instruct", "Qwen/Qwen3-Embedding-4B", "Qwen/Qwen3-Embedding-8B", "Qwen/Qwen3-Next-80B-A3B-Instruct", "Qwen/Qwen3-Next-80B-A3B-Thinking", "deepseek-ai/DeepSeek-R1-0528", "deepseek-ai/Deepseek-V3-0324", "moonshotai/Kimi-K2-Instruct", "moonshotai/Kimi-K2-Instruct-0905", "zai-org/GLM-4.5", "zai-org/GLM-4.5-Air", "zai-org/GLM-4.6"]

[inception]
id = "inception"
name = "Inception"
env = ["INCEPTION_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.inceptionlabs.ai/v1/"
doc = "https://platform.inceptionlabs.ai/docs"
models = ["mercury", "mercury-coder"]

[inference]
id = "inference"
name = "Inference"
env = ["INFERENCE_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://inference.net/v1"
doc = "https://inference.net/models"
models = ["google/gemma-3", "meta/llama-3.1-8b-instruct", "meta/llama-3.2-11b-vision-instruct", "meta/llama-3.2-1b-instruct", "meta/llama-3.2-3b-instruct", "mistral/mistral-nemo-12b-instruct", "osmosis/osmosis-structure-0.6b", "qwen/qwen-2.5-7b-vision-instruct", "qwen/qwen3-embedding-4b"]

[llama]
id = "llama"
name = "Llama"
env = ["LLAMA_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.llama.com/compat/v1/"
doc = "https://llama.developer.meta.com/docs/models"
models = ["cerebras-llama-4-maverick-17b-128e-instruct", "cerebras-llama-4-scout-17b-16e-instruct", "groq-llama-4-maverick-17b-128e-instruct", "llama-3.3-70b-instruct", "llama-3.3-8b-instruct", "llama-4-maverick-17b-128e-instruct-fp8", "llama-4-scout-17b-16e-instruct-fp8"]

[lmstudio]
id = "lmstudio"
name = "LMStudio"
env = ["LMSTUDIO_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "http://127.0.0.1:1234/v1"
doc = "https://lmstudio.ai/models"
models = ["openai/gpt-oss-20b", "qwen/qwen3-30b-a3b-2507", "qwen/qwen3-coder-30b"]

[lucidquery]
id = "lucidquery"
name = "LucidQuery AI"
env = ["LUCIDQUERY_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://lucidquery.com/api/v1"
doc = "https://lucidquery.com/api/docs"
models = ["lucidnova-rf1-100b", "lucidquery-nexus-coder"]

[mistral]
id = "mistral"
name = "Mistral"
env = ["MISTRAL_API_KEY"]
npm = "@ai-sdk/mistral"
doc = "https://docs.mistral.ai/getting-started/models/"
models = ["codestral-latest", "devstral-medium-2507", "devstral-small-2505", "devstral-small-2507", "magistral-medium-latest", "magistral-small", "ministral-3b-latest", "ministral-8b-latest", "mistral-large-latest", "mistral-medium-2505", "mistral-medium-2508", "mistral-medium-latest", "mistral-nemo", "mistral-small-latest", "open-mistral-7b", "open-mixtral-8x22b", "open-mixtral-8x7b", "pixtral-12b", "pixtral-large-latest"]

[modelscope]
id = "modelscope"
name = "ModelScope"
env = ["MODELSCOPE_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api-inference.modelscope.cn/v1"
doc = "https://modelscope.cn/docs/model-service/API-Inference/intro"
models = ["Qwen/Qwen3-235B-A22B-Instruct-2507", "Qwen/Qwen3-235B-A22B-Thinking-2507", "Qwen/Qwen3-30B-A3B-Instruct-2507", "Qwen/Qwen3-30B-A3B-Thinking-2507", "Qwen/Qwen3-Coder-30B-A3B-Instruct", "ZhipuAI/GLM-4.5", "ZhipuAI/GLM-4.6"]

[moonshotai]
id = "moonshotai"
name = "Moonshot AI"
env = ["MOONSHOT_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.moonshot.ai/v1"
doc = "https://platform.moonshot.ai/docs/api/chat"
models = ["kimi-k2-0711-preview", "kimi-k2-0905-preview", "kimi-k2-turbo-preview"]

[moonshotai-cn]
id = "moonshotai-cn"
name = "Moonshot AI (China)"
env = ["MOONSHOT_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.moonshot.cn/v1"
doc = "https://platform.moonshot.cn/docs/api/chat"
models = ["kimi-k2-0711-preview", "kimi-k2-0905-preview", "kimi-k2-turbo-preview"]

[morph]
id = "morph"
name = "Morph"
env = ["MORPH_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.morphllm.com/v1"
doc = "https://docs.morphllm.com/api-reference/introduction"
models = ["auto", "morph-v3-fast", "morph-v3-large"]

[nebius]
id = "nebius"
name = "Nebius AI Studio"
env = ["NEBIUS_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.studio.nebius.com/v1/"
doc = "https://docs.studio.nebius.com/quickstart"
models = ["NousResearch/hermes-4-405b", "NousResearch/hermes-4-70b", "deepseek-ai/deepseek-v3", "meta-llama/llama-3.3-70b-instruct-base", "meta-llama/llama-3.3-70b-instruct-fast", "meta-llama/llama-3_1-405b-instruct", "moonshotai/kimi-k2-instruct", "nvidia/llama-3_1-nemotron-ultra-253b-v1", "openai/gpt-oss-120b", "openai/gpt-oss-20b", "qwen/qwen3-235b-a22b-instruct-2507", "qwen/qwen3-235b-a22b-thinking-2507", "qwen/qwen3-coder-480b-a35b-instruct", "zai-org/glm-4.5", "zai-org/glm-4.5-air"]

[nvidia]
id = "nvidia"
name = "Nvidia"
env = ["NVIDIA_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://integrate.api.nvidia.com/v1"
doc = "https://docs.api.nvidia.com/nim/"
models = ["black-forest-labs/flux.1-dev", "deepseek-ai/deepseek-v3.1", "deepseek-ai/deepseek-v3.1-terminus", "google/gemma-3-27b-it", "microsoft/phi-4-mini-instruct", "moonshotai/kimi-k2-instruct", "moonshotai/kimi-k2-instruct-0905", "nvidia/cosmos-nemotron-34b", "nvidia/llama-3.1-nemotron-ultra-253b-v1", "nvidia/llama-embed-nemotron-8b", "nvidia/nemoretriever-ocr-v1", "nvidia/parakeet-tdt-0.6b-v2", "openai/gpt-oss-120b", "openai/whisper-large-v3", "qwen/qwen3-235b-a22b", "qwen/qwen3-coder-480b-a35b-instruct"]

[openai]
id = "openai"
name = "OpenAI"
env = ["OPENAI_API_KEY"]
npm = "@ai-sdk/openai"
doc = "https://platform.openai.com/docs/models"
models = ["codex-mini-latest", "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo", "gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano", "gpt-4o", "gpt-4o-2024-05-13", "gpt-4o-2024-08-06", "gpt-4o-2024-11-20", "gpt-4o-mini", "gpt-5", "gpt-5-chat-latest", "gpt-5-codex", "gpt-5-mini", "gpt-5-nano", "o1", "o1-mini", "o1-preview", "o1-pro", "o3", "o3-deep-research", "o3-mini", "o3-pro", "o4-mini", "o4-mini-deep-research", "text-embedding-3-large", "text-embedding-3-small", "text-embedding-ada-002"]

[opencode]
id = "opencode"
name = "OpenCode Zen"
env = ["OPENCODE_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://opencode.ai/zen/v1"
doc = "https://opencode.ai/docs/zen"
models = ["an-gbt", "big-pickle", "claude-3-5-haiku", "claude-haiku-4-5", "claude-opus-4-1", "claude-sonnet-4", "claude-sonnet-4-5", "code-supernova", "glm-4.6", "gpt-5", "gpt-5-codex", "grok-code", "kimi-k2", "qwen3-coder"]

[openrouter]
id = "openrouter"
name = "OpenRouter"
env = ["OPENROUTER_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://openrouter.ai/api/v1"
doc = "https://openrouter.ai/models"
models = ["anthropic/claude-3.5-haiku", "anthropic/claude-3.7-sonnet", "anthropic/claude-haiku-4.5", "anthropic/claude-opus-4", "anthropic/claude-opus-4.1", "anthropic/claude-sonnet-4", "anthropic/claude-sonnet-4.5", "cognitivecomputations/dolphin3.0-mistral-24b", "cognitivecomputations/dolphin3.0-r1-mistral-24b", "deepseek/deepseek-chat-v3-0324", "deepseek/deepseek-chat-v3.1", "deepseek/deepseek-r1-0528-qwen3-8b:free", "deepseek/deepseek-r1-0528:free", "deepseek/deepseek-r1-distill-llama-70b", "deepseek/deepseek-r1-distill-qwen-14b", "deepseek/deepseek-r1:free", "deepseek/deepseek-v3-base:free", "deepseek/deepseek-v3.1-terminus", "featherless/qwerky-72b", "google/gemini-2.0-flash-001", "google/gemini-2.0-flash-exp:free", "google/gemini-2.5-flash", "google/gemini-2.5-flash-lite", "google/gemini-2.5-flash-lite-preview-09-2025", "google/gemini-2.5-flash-preview-09-2025", "google/gemini-2.5-pro", "google/gemini-2.5-pro-preview-05-06", "google/gemini-2.5-pro-preview-06-05", "google/gemma-2-9b-it:free", "google/gemma-3-12b-it", "google/gemma-3-27b-it", "google/gemma-3n-e4b-it", "google/gemma-3n-e4b-it:free", "meta-llama/llama-3.2-11b-vision-instruct", "meta-llama/llama-3.3-70b-instruct:free", "meta-llama/llama-4-scout:free", "microsoft/mai-ds-r1:free", "mistralai/codestral-2508", "mistralai/devstral-medium-2507", "mistralai/devstral-small-2505", "mistralai/devstral-small-2505:free", "mistralai/devstral-small-2507", "mistralai/mistral-7b-instruct:free", "mistralai/mistral-medium-3", "mistralai/mistral-medium-3.1", "mistralai/mistral-nemo:free", "mistralai/mistral-small-3.1-24b-instruct", "mistralai/mistral-small-3.2-24b-instruct", "mistralai/mistral-small-3.2-24b-instruct:free", "moonshotai/kimi-dev-72b:free", "moonshotai/kimi-k2", "moonshotai/kimi-k2-0905", "moonshotai/kimi-k2:free", "nousresearch/deephermes-3-llama-3-8b-preview", "nousresearch/hermes-4-405b", "nousresearch/hermes-4-70b", "openai/gpt-4.1", "openai/gpt-4.1-mini", "openai/gpt-4o-mini", "openai/gpt-5", "openai/gpt-5-chat", "openai/gpt-5-codex", "openai/gpt-5-image", "openai/gpt-5-mini", "openai/gpt-5-nano", "openai/gpt-oss-120b", "openai/gpt-oss-20b", "openai/o4-mini", "openrouter/cypher-alpha:free", "openrouter/horizon-alpha", "openrouter/horizon-beta", "openrouter/sonoma-dusk-alpha", "openrouter/sonoma-sky-alpha", "qwen/qwen-2.5-coder-32b-instruct", "qwen/qwen2.5-vl-32b-instruct:free", "qwen/qwen2.5-vl-72b-instruct", "qwen/qwen2.5-vl-72b-instruct:free", "qwen/qwen3-14b:free", "qwen/qwen3-235b-a22b-07-25", "qwen/qwen3-235b-a22b-07-25:free", "qwen/qwen3-235b-a22b-thinking-2507", "qwen/qwen3-235b-a22b:free", "qwen/qwen3-30b-a3b-instruct-2507", "qwen/qwen3-30b-a3b-thinking-2507", "qwen/qwen3-30b-a3b:free", "qwen/qwen3-32b:free", "qwen/qwen3-8b:free", "qwen/qwen3-coder", "qwen/qwen3-coder:free", "qwen/qwen3-max", "qwen/qwen3-next-80b-a3b-instruct", "qwen/qwen3-next-80b-a3b-thinking", "qwen/qwq-32b:free", "rekaai/reka-flash-3", "sarvamai/sarvam-m:free", "thudm/glm-z1-32b:free", "tngtech/deepseek-r1t2-chimera:free", "x-ai/grok-3", "x-ai/grok-3-beta", "x-ai/grok-3-mini", "x-ai/grok-3-mini-beta", "x-ai/grok-4", "x-ai/grok-4-fast", "x-ai/grok-4-fast:free", "x-ai/grok-code-fast-1", "z-ai/glm-4.5", "z-ai/glm-4.5-air", "z-ai/glm-4.5-air:free", "z-ai/glm-4.5v", "z-ai/glm-4.6"]

[perplexity]
id = "perplexity"
name = "Perplexity"
env = ["PERPLEXITY_API_KEY"]
npm = "@perplexity-ai/perplexity_ai"
doc = "https://docs.perplexity.ai"
models = ["sonar", "sonar-pro", "sonar-reasoning", "sonar-reasoning-pro"]

[requesty]
id = "requesty"
name = "Requesty"
env = ["REQUESTY_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://router.requesty.ai/v1"
doc = "https://requesty.ai/solution/llm-routing/models"
models = ["anthropic/claude-3-7-sonnet", "anthropic/claude-4-sonnet-20250522", "anthropic/claude-opus-4", "anthropic/claude-opus-4-1-20250805", "google/gemini-2.5-flash", "google/gemini-2.5-pro", "openai/gpt-4.1", "openai/gpt-4.1-mini", "openai/gpt-4o-mini", "openai/gpt-5", "openai/gpt-5-mini", "openai/gpt-5-nano", "openai/o4-mini"]

[scaleway]
id = "scaleway"
name = "Scaleway"
env = ["SCALEWAY_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.scaleway.ai/v1"
doc = "https://www.scaleway.com/en/docs/generative-apis/"
models = ["deepseek-r1-distill-llama-70b", "gemma-3-27b-it", "gpt-oss-120b", "llama-3.1-8b-instruct", "llama-3.3-70b-instruct", "mistral-nemo-instruct-2407", "mistral-small-3.2-24b-instruct-2506", "pixtral-12b-2409", "qwen3-235b-a22b-instruct-2507", "qwen3-coder-30b-a3b-instruct", "voxtral-small-24b-2507"]

[submodel]
id = "submodel"
name = "submodel"
env = ["SUBMODEL_INSTAGEN_ACCESS_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://llm.submodel.ai/v1"
doc = "https://submodel.gitbook.io"
models = ["Qwen/Qwen3-235B-A22B-Instruct-2507", "Qwen/Qwen3-235B-A22B-Thinking-2507", "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8", "deepseek-ai/DeepSeek-R1-0528", "deepseek-ai/DeepSeek-V3-0324", "deepseek-ai/DeepSeek-V3.1", "openai/gpt-oss-120b", "zai-org/GLM-4.5-Air", "zai-org/GLM-4.5-FP8"]

[synthetic]
id = "synthetic"
name = "Synthetic"
env = ["SYNTHETIC_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.synthetic.new/v1"
doc = "https://synthetic.new/pricing"
models = ["hf:Qwen/Qwen2.5-Coder-32B-Instruct", "hf:Qwen/Qwen3-235B-A22B-Instruct-2507", "hf:Qwen/Qwen3-235B-A22B-Thinking-2507", "hf:Qwen/Qwen3-Coder-480B-A35B-Instruct", "hf:deepseek-ai/DeepSeek-R1", "hf:deepseek-ai/DeepSeek-R1-0528", "hf:deepseek-ai/DeepSeek-V3", "hf:deepseek-ai/DeepSeek-V3-0324", "hf:deepseek-ai/DeepSeek-V3.1", "hf:deepseek-ai/DeepSeek-V3.1-Terminus", "hf:meta-llama/Llama-3.1-405B-Instruct", "hf:meta-llama/Llama-3.1-70B-Instruct", "hf:meta-llama/Llama-3.1-8B-Instruct", "hf:meta-llama/Llama-3.3-70B-Instruct", "hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "hf:meta-llama/Llama-4-Scout-17B-16E-Instruct", "hf:moonshotai/Kimi-K2-Instruct", "hf:moonshotai/Kimi-K2-Instruct-0905", "hf:openai/gpt-oss-120b", "hf:zai-org/GLM-4.5", "hf:zai-org/GLM-4.6"]

[togetherai]
id = "togetherai"
name = "Together AI"
env = ["TOGETHER_API_KEY"]
npm = "@ai-sdk/togetherai"
doc = "https://docs.together.ai/docs/serverless-models"
models = ["Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8", "deepseek-ai/DeepSeek-R1", "deepseek-ai/DeepSeek-V3", "meta-llama/Llama-3.3-70B-Instruct-Turbo", "moonshotai/Kimi-K2-Instruct", "openai/gpt-oss-120b"]

[upstage]
id = "upstage"
name = "Upstage"
env = ["UPSTAGE_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.upstage.ai"
doc = "https://developers.upstage.ai/docs/apis/chat"
models = ["solar-mini", "solar-pro2"]

[v0]
id = "v0"
name = "v0"
env = ["V0_API_KEY"]
npm = "@ai-sdk/vercel"
doc = "https://sdk.vercel.ai/providers/ai-sdk-providers/vercel"
models = ["v0-1.0-md", "v0-1.5-lg", "v0-1.5-md"]

[venice]
id = "venice"
name = "Venice AI"
env = ["VENICE_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.venice.ai/api/v1"
doc = "https://docs.venice.ai"
models = ["deepseek-coder-v2-lite", "deepseek-r1-671b", "dolphin-2.9.2-qwen2-72b", "llama-3.1-405b", "llama-3.2-3b", "llama-3.3-70b", "mistral-31-24b", "qwen-2.5-coder-32b", "qwen-2.5-qwq-32b", "qwen-2.5-vl", "qwen3-235b", "qwen3-4b", "venice-uncensored"]

[vercel]
id = "vercel"
name = "Vercel AI Gateway"
env = ["AI_GATEWAY_API_KEY"]
npm = "@ai-sdk/gateway"
doc = "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway"
models = ["alibaba/qwen3-coder-plus", "alibaba/qwen3-max", "alibaba/qwen3-next-80b-a3b-instruct", "alibaba/qwen3-next-80b-a3b-thinking", "alibaba/qwen3-vl-instruct", "alibaba/qwen3-vl-thinking", "amazon/nova-lite", "amazon/nova-micro", "amazon/nova-pro", "anthropic/claude-3-5-haiku", "anthropic/claude-3-haiku", "anthropic/claude-3-opus", "anthropic/claude-3.5-sonnet", "anthropic/claude-3.7-sonnet", "anthropic/claude-4-1-opus", "anthropic/claude-4-opus", "anthropic/claude-4-sonnet", "anthropic/claude-4.5-sonnet", "anthropic/claude-haiku-4.5", "cerebras/qwen3-coder", "deepseek/deepseek-r1", "deepseek/deepseek-r1-distill-llama-70b", "deepseek/deepseek-v3.1-terminus", "deepseek/deepseek-v3.2-exp", "deepseek/deepseek-v3.2-exp-thinking", "google/gemini-2.0-flash", "google/gemini-2.0-flash-lite", "google/gemini-2.5-flash", "google/gemini-2.5-flash-lite", "google/gemini-2.5-flash-lite-preview-09-2025", "google/gemini-2.5-flash-preview-09-2025", "google/gemini-2.5-pro", "meta/llama-3.3-70b", "meta/llama-4-maverick", "meta/llama-4-scout", "mistral/codestral", "mistral/magistral-medium", "mistral/magistral-small", "mistral/ministral-3b", "mistral/ministral-8b", "mistral/mistral-large", "mistral/mistral-small", "mistral/mixtral-8x22b-instruct", "mistral/pixtral-12b", "mistral/pixtral-large", "moonshotai/kimi-k2", "morph/morph-v3-fast", "morph/morph-v3-large", "openai/gpt-4-turbo", "openai/gpt-4.1", "openai/gpt-4.1-mini", "openai/gpt-4.1-nano", "openai/gpt-4o", "openai/gpt-4o-mini", "openai/gpt-5", "openai/gpt-5-codex", "openai/gpt-5-mini", "openai/gpt-5-nano", "openai/gpt-oss-120b", "openai/gpt-oss-20b", "openai/o1", "openai/o3", "openai/o3-mini", "openai/o4-mini", "perplexity/sonar", "perplexity/sonar-pro", "perplexity/sonar-reasoning", "perplexity/sonar-reasoning-pro", "vercel/v0-1.0-md", "vercel/v0-1.5-md", "xai/grok-2", "xai/grok-2-vision", "xai/grok-3", "xai/grok-3-fast", "xai/grok-3-mini", "xai/grok-3-mini-fast", "xai/grok-4", "xai/grok-4-fast", "xai/grok-4-fast-non-reasoning", "xai/grok-code-fast-1", "zai/glm-4.5", "zai/glm-4.5-air", "zai/glm-4.5v", "zai/glm-4.6"]

[vultr]
id = "vultr"
name = "Vultr"
env = ["VULTR_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.vultrinference.com/v1"
doc = "https://api.vultrinference.com/"
models = ["deepseek-r1-distill-llama-70b", "deepseek-r1-distill-qwen-32b", "gpt-oss-120b", "kimi-k2-instruct", "qwen2.5-coder-32b-instruct"]

[wandb]
id = "wandb"
name = "Weights & Biases"
env = ["WANDB_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.inference.wandb.ai/v1"
doc = "https://weave-docs.wandb.ai/guides/integrations/inference/"
models = ["Qwen/Qwen3-235B-A22B-Instruct-2507", "Qwen/Qwen3-235B-A22B-Thinking-2507", "Qwen/Qwen3-Coder-480B-A35B-Instruct", "deepseek-ai/DeepSeek-R1-0528", "deepseek-ai/DeepSeek-V3-0324", "meta-llama/Llama-3.1-8B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "meta-llama/Llama-4-Scout-17B-16E-Instruct", "microsoft/Phi-4-mini-instruct", "moonshotai/Kimi-K2-Instruct"]

[xai]
id = "xai"
name = "xAI"
env = ["XAI_API_KEY"]
npm = "@ai-sdk/xai"
doc = "https://docs.x.ai/docs/models"
models = ["grok-2", "grok-2-1212", "grok-2-latest", "grok-2-vision", "grok-2-vision-1212", "grok-2-vision-latest", "grok-3", "grok-3-fast", "grok-3-fast-latest", "grok-3-latest", "grok-3-mini", "grok-3-mini-fast", "grok-3-mini-fast-latest", "grok-3-mini-latest", "grok-4", "grok-4-fast", "grok-4-fast-non-reasoning", "grok-beta", "grok-code-fast-1", "grok-vision-beta"]

[zai]
id = "zai"
name = "Z.AI"
env = ["ZHIPU_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.z.ai/api/paas/v4"
doc = "https://docs.z.ai/guides/overview/pricing"
models = ["glm-4.5", "glm-4.5-air", "glm-4.5-flash", "glm-4.5v", "glm-4.6"]

[zai-coding-plan]
id = "zai-coding-plan"
name = "Z.AI Coding Plan"
env = ["ZHIPU_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://api.z.ai/api/coding/paas/v4"
doc = "https://docs.z.ai/devpack/overview"
models = ["glm-4.5", "glm-4.5-air", "glm-4.5-flash", "glm-4.5v", "glm-4.6"]

[zhipuai]
id = "zhipuai"
name = "Zhipu AI"
env = ["ZHIPU_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://open.bigmodel.cn/api/paas/v4"
doc = "https://docs.z.ai/guides/overview/pricing"
models = ["glm-4.5", "glm-4.5-air", "glm-4.5-flash", "glm-4.5v", "glm-4.6"]

[zhipuai-coding-plan]
id = "zhipuai-coding-plan"
name = "Zhipu AI Coding Plan"
env = ["ZHIPU_API_KEY"]
npm = "@ai-sdk/openai-compatible"
api = "https://open.bigmodel.cn/api/coding/paas/v4"
doc = "https://docs.bigmodel.cn/cn/coding-plan/overview"
models = ["glm-4.5", "glm-4.5-air", "glm-4.5-flash", "glm-4.5v", "glm-4.6"]
